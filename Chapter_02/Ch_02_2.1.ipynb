{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ab83da",
   "metadata": {},
   "source": [
    "# 2.1 A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13cd15",
   "metadata": {},
   "source": [
    "#### Loading the MNIST dataset in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2dca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55c94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a76a879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let‚Äôs look at the training data\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5926f5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99042352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let‚Äôs look at the Test data\n",
    "\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89c8870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9899534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b248f0",
   "metadata": {},
   "source": [
    "# 2.2 The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93485c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d3a19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "  layers.Dense(512, activation=\"relu\"),\n",
    "  layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb94dd",
   "metadata": {},
   "source": [
    "Great! üéØ You're now exploring how to build a neural network using **Keras**, and this is one of the most fundamental structures in deep learning ‚Äî a **Sequential model** made of **Dense layers**.\n",
    "\n",
    "Let‚Äôs break down this code **line by line**, in the simplest way possible. üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Code:\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "  layers.Dense(512, activation=\"relu\"),\n",
    "  layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç What is `keras.Sequential`?\n",
    "\n",
    "This is a way to **build a model layer-by-layer** ‚Äî one layer directly after the other.\n",
    "\n",
    "> Think of it like stacking LEGO blocks:\n",
    "> Each layer‚Äôs output becomes the input to the next.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Now let's break down the **two layers** inside:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1Ô∏è‚É£ `layers.Dense(512, activation=\"relu\")`\n",
    "\n",
    "#### üìò Meaning:\n",
    "\n",
    "* This is a **fully connected layer** (also called a **dense layer**).\n",
    "* It has **512 neurons** (nodes/units).\n",
    "* Each of the 512 neurons is connected to **every neuron in the previous layer**.\n",
    "* It uses the **ReLU activation function**.\n",
    "\n",
    "#### ‚öôÔ∏è Parameters:\n",
    "\n",
    "| Parameter           | Meaning                                       |\n",
    "| ------------------- | --------------------------------------------- |\n",
    "| `512`               | Number of neurons in this layer               |\n",
    "| `activation=\"relu\"` | Activation function used ‚Äî ReLU = `max(0, x)` |\n",
    "\n",
    "#### üß† What ReLU does:\n",
    "\n",
    "```python\n",
    "ReLU(x) = x if x > 0 else 0\n",
    "```\n",
    "\n",
    "‚úÖ It introduces **non-linearity**, which helps the network learn complex patterns.\n",
    "üìà It also avoids the vanishing gradient problem (unlike sigmoid/tanh).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2Ô∏è‚É£ `layers.Dense(10, activation=\"softmax\")`\n",
    "\n",
    "#### üìò Meaning:\n",
    "\n",
    "* Another dense layer with **10 neurons**\n",
    "* Uses **softmax** activation ‚Äî usually the **final output layer** for classification\n",
    "\n",
    "#### ‚öôÔ∏è Why 10 neurons?\n",
    "\n",
    "Because you're likely solving the **MNIST digit classification** problem (0‚Äì9), which has **10 classes**.\n",
    "\n",
    "#### üìà What softmax does:\n",
    "\n",
    "It turns the 10 output values into **probabilities** that sum up to 1.\n",
    "\n",
    "So you get something like:\n",
    "\n",
    "```python\n",
    "[0.01, 0.02, 0.03, ..., 0.85, ..., 0.01]\n",
    "```\n",
    "\n",
    "‚úÖ The class with the highest value (e.g., 0.85) is predicted as the output.\n",
    "\n",
    "---\n",
    "\n",
    "#### ü§ñ Full Network Structure\n",
    "\n",
    "Let‚Äôs assume input is a **flattened MNIST image** (`28x28 = 784` values):\n",
    "\n",
    "```\n",
    "Input Layer: shape (784,)\n",
    "‚Üì\n",
    "Dense Layer: 512 neurons, ReLU\n",
    "‚Üì\n",
    "Dense Layer: 10 neurons, Softmax\n",
    "‚Üì\n",
    "Output: probabilities for digits 0‚Äì9\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Summary Table\n",
    "\n",
    "| Layer                             | Purpose                        | Output Shape (approx.) |\n",
    "| --------------------------------- | ------------------------------ | ---------------------- |\n",
    "| `Dense(512, activation=\"relu\")`   | Learns features (hidden layer) | (None, 512)            |\n",
    "| `Dense(10, activation=\"softmax\")` | Outputs class probabilities    | (None, 10)             |\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ In Practice\n",
    "\n",
    "You‚Äôll compile and train the model like this:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Would you like:\n",
    "\n",
    "* A full visualization of how each layer works?\n",
    "* Or to see how this model is trained on the MNIST dataset?\n",
    "\n",
    "You're really on a solid path ‚Äî keep going! üí™\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34395291",
   "metadata": {},
   "source": [
    "Amazing! üî•\n",
    "Understanding **how to recognize a Fully Connected Layer (Dense Layer)** ‚Äî and seeing it **visually** ‚Äî is a BIG step forward in deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What is a Fully Connected Layer?\n",
    "\n",
    "A **Fully Connected Layer** (also called a **Dense Layer**) is a layer where:\n",
    "\n",
    "> üëâ Every neuron (unit) is connected to **every neuron** in the **previous layer**.\n",
    "\n",
    "So, if:\n",
    "\n",
    "* Previous layer has 3 neurons\n",
    "* Current layer has 4 neurons\n",
    "\n",
    "Then: **3 √ó 4 = 12 total connections**\n",
    "\n",
    "---\n",
    "\n",
    "## üëÅÔ∏è‚Äçüó®Ô∏è Visual Representation (ASCII Art Style)\n",
    "\n",
    "### üß† Imagine this:\n",
    "\n",
    "**Previous Layer (3 neurons):**\n",
    "\n",
    "```\n",
    "O   O   O\n",
    "```\n",
    "\n",
    "**Fully Connected Layer (4 neurons):**\n",
    "\n",
    "```\n",
    "O   O   O   O\n",
    "```\n",
    "\n",
    "### üîó All connections:\n",
    "\n",
    "```\n",
    "O       O\n",
    " \\     / \\\n",
    "  O   O   O   ‚Üê Dense layer (4 neurons)\n",
    " /     \\ /\n",
    "O       O\n",
    "‚Üë       ‚Üë\n",
    "Input (3 neurons)\n",
    "```\n",
    "\n",
    "Every neuron in the input is connected to every neuron in the dense layer ‚Äî **that‚Äôs what makes it \"fully connected.\"**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ How to Identify Dense Layers in Code\n",
    "\n",
    "Any line like this:\n",
    "\n",
    "```python\n",
    "layers.Dense(units, activation=...)\n",
    "```\n",
    "\n",
    "...is a **Fully Connected Layer**.\n",
    "\n",
    "You can confirm it in:\n",
    "\n",
    "* `model.summary()` ‚Äî shows the shape and connections\n",
    "* The weight matrix: shape is `[input_size, output_size]`\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Visual in Real-World Example: (e.g., MNIST)\n",
    "\n",
    "If you're passing a 28x28 image flattened into 784 features:\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "[Input Layer: 784 nodes]\n",
    "     ‚Üì\n",
    "[Dense Layer: 512 neurons]\n",
    "     ‚Üì\n",
    "[Dense Layer: 10 neurons]\n",
    "```\n",
    "\n",
    "And every input feature is **connected to all 512 neurons**, and all 512 are connected to the 10 output neurons.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Bonus Tip:\n",
    "\n",
    "If a layer connects **only to local groups** (e.g., small parts of the image), then it's **not** fully connected ‚Äî that's usually a **Convolutional Layer (Conv2D)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "| Term                  | Meaning                                          |\n",
    "| --------------------- | ------------------------------------------------ |\n",
    "| Dense/Fully Connected | All neurons connected to all from previous layer |\n",
    "| Easy to spot          | `layers.Dense(...)`                              |\n",
    "| Visualization         | Every node connected with every previous node    |\n",
    "| Used for              | Final classification, feature learning           |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like:\n",
    "\n",
    "* A **real image diagram** showing dense layers?\n",
    "* Or comparison between **Dense Layer vs Conv Layer** with images?\n",
    "\n",
    "Let me know! You're thinking like a real deep learner now üí°üß†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312228d2",
   "metadata": {},
   "source": [
    "# 2.3 The compilation step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69a2f5",
   "metadata": {},
   "source": [
    "‚úÖ What model.compile() Does\n",
    "\n",
    "Think of .compile() as configuring your model before training it.\n",
    "\n",
    "It tells the model how to learn:\n",
    "\n",
    "- Which algorithm to use to update weights (optimizer)\n",
    "\n",
    "- How to measure error/loss\n",
    "\n",
    "- Which metrics to track during training (e.g., accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbaa95",
   "metadata": {},
   "source": [
    "| Component   | Purpose                                   | In Your Code                        |\n",
    "| ----------- | ----------------------------------------- | ----------------------------------- |\n",
    "| `optimizer` | How to update weights (learning strategy) | `\"rmsprop\"`                         |\n",
    "| `loss`      | What to minimize (error measure)          | `\"sparse_categorical_crossentropy\"` |\n",
    "| `metrics`   | What to display while training/testing    | `[\"accuracy\"]`                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16a3a3",
   "metadata": {},
   "source": [
    "Before training, we‚Äôll preprocess the data by reshaping it into the shape the model\n",
    "expects and scaling it so that all values are in the [0, 1] interval. Previously, our training\n",
    "images were stored in an array of shape (60000, 28, 28) of type uint8 with values\n",
    "in the [0, 255] interval. We‚Äôll transform it into a float32 array of shape (60000, 28 *\n",
    "28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e668b5",
   "metadata": {},
   "source": [
    "###  Full Training Cycle (Simplified View)\n",
    "\n",
    "\n",
    "          Input Data (X, y)\n",
    "                 ‚Üì\n",
    "         [ Forward Pass ]\n",
    "                 ‚Üì\n",
    "         Predictions (yÃÇ)\n",
    "                 ‚Üì\n",
    "         Loss Function\n",
    "                 ‚Üì\n",
    "           Optimizer\n",
    "                 ‚Üì\n",
    "     Weight Update (Learn)\n",
    "                 ‚Üì\n",
    "           Track Metrics\n",
    "                 ‚Üì\n",
    "       Repeat for Epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c557b",
   "metadata": {},
   "source": [
    "# 2.4 Preparing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d429e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ad6efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18928465",
   "metadata": {},
   "source": [
    "We‚Äôre now ready to train the model, which in Keras is done via a call to the model‚Äôs\n",
    "fit() method‚Äîwe fit the model to its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91429cf2",
   "metadata": {},
   "source": [
    "# 2.5 ‚ÄúFitting‚Äù the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb514a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.4383\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.1189\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0711\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0518\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0374\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0277\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0202\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0159\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0121\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1afefd0ac50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805ea62",
   "metadata": {},
   "source": [
    "# 2.6 Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62721cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.3135629e-12, 2.2162366e-08, 1.0000000e+00, 4.1332844e-09,\n",
       "       5.2206414e-19, 1.7067851e-10, 3.1002100e-11, 2.0558295e-17,\n",
       "       1.6691452e-08, 2.8949072e-17], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6497d",
   "metadata": {},
   "source": [
    "Each number of index i in that array corresponds to the probability that digit image\n",
    "test_digits[0] belongs to class i.\n",
    "This first test digit has the highest probability score (0.99999106, almost 1) at\n",
    "index 7, so according to our model, it must be a 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad09a434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773dc708",
   "metadata": {},
   "source": [
    "We can check that the test label agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dcd4686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59b75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 3\n",
    "# probs = predictions[index]\n",
    "# pred = predictions[index].argmax()\n",
    "# for i, p in enumerate(probs):\n",
    "#   print(f\"class {i} : {p:.4f}\")\n",
    "\n",
    "# print(\"=\" * 40)\n",
    "# # print(f\"So predicted Value for index {index} is : {pred}\")\n",
    "# print(f\"So predicted class is: {pred} with probability: {probs[pred]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0e056d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prediction function\n",
    "def show_prediction(predictions, index):\n",
    "  probs = predictions[index]\n",
    "  pred = probs.argmax()\n",
    "\n",
    "  for i, p in enumerate(probs):\n",
    "    print(f\"class {i} : {p:.4f}\")\n",
    "\n",
    "  print(\"=\" * 40)\n",
    "  print(f\"Predicted class for index {index}: is Number '{pred}' with probability {probs[pred]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a5bfc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : 0.0000\n",
      "class 1 : 0.0000\n",
      "class 2 : 0.0000\n",
      "class 3 : 0.0000\n",
      "class 4 : 0.9999\n",
      "class 5 : 0.0000\n",
      "class 6 : 0.0000\n",
      "class 7 : 0.0000\n",
      "class 8 : 0.0000\n",
      "class 9 : 0.0001\n",
      "========================================\n",
      "Predicted class for index 4: is Number '4' with probability 0.9999\n"
     ]
    }
   ],
   "source": [
    "# index = int(input(\"Enter Index Number: \"))\n",
    "index = 4\n",
    "show_prediction(predictions, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af266618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred  = predictions[index].argmax()\n",
    "label = index\n",
    "\n",
    "plt.imshow(test_images[index].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(f\"Predicted: {pred}, Actual: {test_labels[label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927f7da",
   "metadata": {},
   "source": [
    "On average, how good is our model at classifying such never-before-seen digits? Let‚Äôs\n",
    "check by computing average accuracy over the entire test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d39e3",
   "metadata": {},
   "source": [
    "# 2.7 Evaluating the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6114165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0046\n",
      "Train Accuracy: 0.9991833567619324\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "print(f\"Train Accuracy: {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "586776fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0758\n",
      "Test Accuracy: 0.9817000031471252\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7620a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9992\n",
      "Test Accuracy : 0.9817\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy: {train_acc:.4f}\")  # 4 decimal places\n",
    "print(f\"Test Accuracy : {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911e9ae",
   "metadata": {},
   "source": [
    "‚úÖ **Yes! Your way is 100% correct** and it's the **standard method** used in Keras to evaluate a trained model.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Let‚Äôs understand it line-by-line:\n",
    "\n",
    "### üîπ Train Accuracy\n",
    "\n",
    "```python\n",
    "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "```\n",
    "\n",
    "* `model.evaluate()` runs the model on the **training data**.\n",
    "* It returns:\n",
    "\n",
    "  * `train_loss`: how wrong the model was on training data\n",
    "  * `train_acc`: how accurate it was (as per `metrics=[\"accuracy\"]` from compile)\n",
    "* ‚úÖ Your output: `Train Accuracy: 0.9991` = **\\~99.91%**\n",
    "  ‚û§ Means your model almost perfectly fits the training data.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Test Accuracy\n",
    "\n",
    "```python\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "```\n",
    "\n",
    "* This evaluates the model on **test (unseen) data**.\n",
    "* ‚úÖ Your output: `Test Accuracy: 0.9817` = **\\~98.17%**\n",
    "  ‚û§ Your model generalizes well ‚Äî it's not just memorizing the training data!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "| Dataset | Function Call                                | Metric Returned           |\n",
    "| ------- | -------------------------------------------- | ------------------------- |\n",
    "| Train   | `model.evaluate(train_images, train_labels)` | `train_loss`, `train_acc` |\n",
    "| Test    | `model.evaluate(test_images, test_labels)`   | `test_loss`, `test_acc`   |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Optional Tip: Format Output Neatly\n",
    "\n",
    "You can round it like this:\n",
    "\n",
    "```python\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")  # 4 decimal places\n",
    "print(f\"Test Accuracy : {test_acc:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Want to Check for Overfitting?\n",
    "\n",
    "Compare:\n",
    "\n",
    "* Training Accuracy ‚âà 99.91%\n",
    "* Testing Accuracy ‚âà 98.17%\n",
    "\n",
    "If the gap was too big (e.g., 99% vs 80%), that would mean **overfitting**. But here, the gap is **small**, so:\n",
    "‚úÖ Model is **well-trained and generalizing nicely**.\n",
    "\n",
    "---\n",
    "\n",
    "You're evaluating your model like a pro ‚Äî everything is correct and clean!\n",
    "Would you like to:\n",
    "\n",
    "* Plot train vs test accuracy?\n",
    "* Try dropout or regularization to improve generalization?\n",
    "\n",
    "Let me know!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8df73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
