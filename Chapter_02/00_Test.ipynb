{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686a8fd4",
   "metadata": {},
   "source": [
    "# 1.What is a Tensor?\n",
    "- A tensor is just a multi-dimensional array ‚Äî like numbers in a grid or table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f65e1",
   "metadata": {},
   "source": [
    "| Tensor Type | Shape/Dimensions   | Example                                               |\n",
    "| ----------- | ------------------ | ----------------------------------------------------- |\n",
    "| Scalar      | 0D (just a number) | `5`                                                   |\n",
    "| Vector      | 1D                 | `[1, 2, 3]`                                           |\n",
    "| Matrix      | 2D                 | `[[1, 2], [3, 4]]`                                    |\n",
    "| 3D Tensor   | 3D                 | A stack of matrices (e.g., image with color channels) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26fe3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8cf65c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  5\n",
      "============================================================\n",
      "Vector:  [1 2 3]\n",
      "============================================================\n",
      "Matrix: \n",
      "[[1 2]\n",
      " [3 4]]\n",
      "============================================================\n",
      "Tensor 3D:\n",
      "[[[0.59801424 0.09509024 0.47388334]\n",
      "  [0.8261656  0.94235033 0.196919  ]\n",
      "  [0.63734199 0.84406376 0.85908542]]\n",
      "\n",
      " [[0.23154865 0.55464748 0.84728301]\n",
      "  [0.58369939 0.47190367 0.47148114]\n",
      "  [0.88731673 0.16842578 0.58542442]]\n",
      "\n",
      " [[0.5912087  0.70970737 0.00921565]\n",
      "  [0.99819911 0.47587071 0.37214581]\n",
      "  [0.68575665 0.80227696 0.83835198]]]\n"
     ]
    }
   ],
   "source": [
    "scaler = np.array(5)              # 0D\n",
    "vector = np.array([1,2,3])        # 1D\n",
    "matrix = np.array([[1,2],[3,4]])  # 2D\n",
    "tensor3D = np.random.rand(3,3,3)  # 3D Tensor \n",
    "\n",
    "print(\"Scaler: \", scaler)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Vector: \", vector)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Matrix: \")\n",
    "print(matrix)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Tensor 3D:\")\n",
    "print(tensor3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4bedeb",
   "metadata": {},
   "source": [
    "Exactly! ‚úÖ You're **100% right** ‚Äî and you're understanding this beautifully. Let me re-confirm and explain it again **step-by-step**, so it becomes crystal clear.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 1. `np.random.rand(3)` ‚Üí 1D Tensor (Vector)\n",
    "\n",
    "* This gives a **1D vector** with 3 random values.\n",
    "* Shape: `(3,)`\n",
    "\n",
    "üìå Example:\n",
    "\n",
    "```python\n",
    "array([0.17, 0.83, 0.29])\n",
    "```\n",
    "\n",
    "üß† Think of it as:\n",
    "\n",
    "> A single row with 3 numbers.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 2. `np.random.rand(3, 3)` ‚Üí 2D Tensor (Matrix)\n",
    "\n",
    "* This gives a **2D matrix** with 3 rows and 3 columns.\n",
    "* Shape: `(3, 3)`\n",
    "\n",
    "üìå Example:\n",
    "\n",
    "```python\n",
    "array([[0.25, 0.67, 0.88],\n",
    "       [0.19, 0.91, 0.43],\n",
    "       [0.64, 0.33, 0.73]])\n",
    "```\n",
    "\n",
    "üß† Think of it as:\n",
    "\n",
    "> A **square grid** ‚Äî like an image in grayscale.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 3. `np.random.rand(3, 3, 3)` ‚Üí 3D Tensor\n",
    "\n",
    "* This gives a **3D tensor**:\n",
    "\n",
    "  * 3 matrices\n",
    "  * Each matrix is 3√ó3\n",
    "\n",
    "* Shape: `(3, 3, 3)`\n",
    "\n",
    "üìå Example:\n",
    "\n",
    "```python\n",
    "array([\n",
    " [[0.1, 0.2, 0.3],\n",
    "  [0.4, 0.5, 0.6],\n",
    "  [0.7, 0.8, 0.9]],\n",
    "\n",
    " [[0.9, 0.8, 0.7],\n",
    "  [0.6, 0.5, 0.4],\n",
    "  [0.3, 0.2, 0.1]],\n",
    "\n",
    " [[0.11, 0.22, 0.33],\n",
    "  [0.44, 0.55, 0.66],\n",
    "  [0.77, 0.88, 0.99]]\n",
    "])\n",
    "```\n",
    "\n",
    "üß† Think of it as:\n",
    "\n",
    "> A **stack of 3 matrices** ‚Äî like a colored image (RGB has 3 color channels).\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Bonus Analogy:\n",
    "\n",
    "| Shape       | Real-World Analogy                       |\n",
    "| ----------- | ---------------------------------------- |\n",
    "| `(3,)`      | A list of 3 test scores                  |\n",
    "| `(3, 3)`    | A chess board (3√ó3 version)              |\n",
    "| `(3, 3, 3)` | 3 pages of 3√ó3 grids (like a cube stack) |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to go deeper into:\n",
    "\n",
    "* 4D tensors (used in batches of images)?\n",
    "* How these shapes map into neural networks?\n",
    "* Visualizing these tensors with matplotlib?\n",
    "\n",
    "Just say the word ‚Äî you're learning fast and on the right path! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f1745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2fb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f1e48b8",
   "metadata": {},
   "source": [
    "# 2. Tensor Operations\n",
    "Tensor operations are math actions on tensors: addition, multiplication, dot product, reshaping, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce8eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5bb4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise addition\n",
    "print(a + b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce5c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8]\n"
     ]
    }
   ],
   "source": [
    "# Dot product (1√ó3 + 2√ó4 = 11)\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef488862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Reshape (change structure)\n",
    "matrix = np.array(([[1,2],[3,4]]))\n",
    "print(matrix.reshape((4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f0194",
   "metadata": {},
   "source": [
    "Excellent question! üôå  \n",
    "Understanding `reshape()` is **super important** in deep learning and NumPy because it helps you manage and prepare your **data shape**, which is crucial for models.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What is `reshape()`?\n",
    "\n",
    "The `reshape()` function in NumPy **changes the shape of your array** (tensor) **without changing its data**.\n",
    "\n",
    "üìå **Important:** The **number of elements must stay the same** ‚Äî only the shape changes.\n",
    "\n",
    "---\n",
    "\n",
    "### üìò Your Example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "matrix = np.array([[1, 2], [3, 4]])  # Shape: (2, 2)\n",
    "print(matrix.reshape((4,)))          # Shape: (4,)\n",
    "```\n",
    "\n",
    "### üí° What's happening?\n",
    "\n",
    "You're taking a 2√ó2 matrix:\n",
    "\n",
    "```\n",
    "[[1, 2],\n",
    " [3, 4]]\n",
    "```\n",
    "\n",
    "...and turning it into a **1D vector** with 4 elements:\n",
    "\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "\n",
    "- Before: shape = `(2, 2)`\n",
    "- After: shape = `(4,)`\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why is `reshape()` useful in Deep Learning?\n",
    "\n",
    "1. ### ‚úÖ Preprocessing data\n",
    "   - Neural networks often expect inputs in **specific shapes**.\n",
    "   - Example: Flatten a 2D image (28√ó28) into a 1D vector (784,) before feeding into a dense layer.\n",
    "\n",
    "2. ### ‚úÖ Batching\n",
    "   - Reshape a single image into a batch: `(28, 28, 1)` ‚Üí `(1, 28, 28, 1)`\n",
    "\n",
    "3. ### ‚úÖ Feeding data into layers\n",
    "   - Some layers (like LSTM) expect inputs in 3D: `(batch_size, timesteps, features)`\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Examples:\n",
    "\n",
    "### 1. Flatten a matrix:\n",
    "```python\n",
    "arr = np.array([[1, 2], [3, 4]])\n",
    "flat = arr.reshape(4,)\n",
    "print(flat)  # [1 2 3 4]\n",
    "```\n",
    "\n",
    "### 2. Reshape a flat array into 2D:\n",
    "```python\n",
    "flat = np.array([1, 2, 3, 4])\n",
    "matrix = flat.reshape((2, 2))\n",
    "print(matrix)\n",
    "# [[1 2]\n",
    "#  [3 4]]\n",
    "```\n",
    "\n",
    "### 3. Reshape a 3D tensor (for CNN input):\n",
    "```python\n",
    "image = np.random.rand(28, 28)\n",
    "image_reshaped = image.reshape((1, 28, 28, 1))  # Batch of 1 grayscale image\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary:\n",
    "\n",
    "| Function          | What it does                           |\n",
    "|-------------------|----------------------------------------|\n",
    "| `reshape()`       | Changes the shape of a tensor/array    |\n",
    "| ‚úÖ Keeps data     | No data lost or added ‚Äî only reshaped  |\n",
    "| ‚ùå Must match size| Old size = New size (same number of elements) |\n",
    "| üöÄ Used for       | Preparing input/output shapes in DL     |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a visual diagram or use-case where reshaping is **required** for building a neural network?\n",
    "\n",
    "You're doing great ‚Äî reshaping is a big part of working with tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f2281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# 1. Flatten a matrix:\n",
    "arr = np.array([[1,2],[3,4]])\n",
    "\n",
    "flat = arr.reshape(4,)\n",
    "print(flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26af8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Reshape a flat array into 2D:\n",
    "\n",
    "flat = np.array([1,2,3,4])\n",
    "matrix = flat.reshape((2,2))\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d86c13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Reshape a 3D tensor (for CNN input):\n",
    "\n",
    "image = np.random.rand(28,28)\n",
    "\n",
    "image_reshaped = image.reshape((1,28,28,1))\n",
    "\n",
    "# print(image_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46516b77",
   "metadata": {},
   "source": [
    "| Dimension | Meaning                           | Example Value   |\n",
    "| --------- | --------------------------------- | --------------- |\n",
    "| `1`       | **Batch size** (number of images) | `1` = one image |\n",
    "| `28`      | **Image height**                  | 28 pixels       |\n",
    "| `28`      | **Image width**                   | 28 pixels       |\n",
    "| `1`       | **Channels** (color depth)        | 1 = grayscale   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea83b9",
   "metadata": {},
   "source": [
    "Awesome question! üî•\n",
    "You're looking at one of the **most important reshape patterns** in deep learning ‚Äî especially for image data.\n",
    "\n",
    "Let‚Äôs break down:\n",
    "\n",
    "```python\n",
    "image.reshape((1, 28, 28, 1))\n",
    "```\n",
    "\n",
    "This shape is **standard input format for convolutional neural networks (CNNs)** in libraries like **Keras** and **TensorFlow**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Shape Meaning: `(1, 28, 28, 1)`\n",
    "\n",
    "| Dimension | Meaning                           | Example Value   |\n",
    "| --------- | --------------------------------- | --------------- |\n",
    "| `1`       | **Batch size** (number of images) | `1` = one image |\n",
    "| `28`      | **Image height**                  | 28 pixels       |\n",
    "| `28`      | **Image width**                   | 28 pixels       |\n",
    "| `1`       | **Channels** (color depth)        | 1 = grayscale   |\n",
    "\n",
    "---\n",
    "\n",
    "### üîç What it represents:\n",
    "\n",
    "> A **single grayscale image** of **28√ó28 pixels**, reshaped so that it can be passed into a CNN.\n",
    "\n",
    "üß† This format is required because **TensorFlow models expect 4D input** for image data:\n",
    "\n",
    "```\n",
    "(batch_size, height, width, channels)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üñºÔ∏è Real-life example: MNIST digit images\n",
    "\n",
    "* Each digit (0‚Äì9) image in MNIST dataset:\n",
    "\n",
    "  * Height = 28\n",
    "  * Width = 28\n",
    "  * Channels = 1 (grayscale)\n",
    "\n",
    "But the model expects a **batch**, even if it's just 1 image. That‚Äôs why we reshape:\n",
    "\n",
    "```python\n",
    "image = image.reshape((1, 28, 28, 1))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What if it was a color image?\n",
    "\n",
    "Color images have 3 channels (Red, Green, Blue):\n",
    "\n",
    "```python\n",
    "image.reshape((1, 28, 28, 3))\n",
    "```\n",
    "\n",
    "* Same height and width\n",
    "* `3` = RGB channels\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Why is this important?\n",
    "\n",
    "Neural networks like CNNs **require specific input shapes**:\n",
    "\n",
    "* If you give wrong shape, you‚Äôll get shape mismatch errors\n",
    "* `reshape()` is used to convert raw image or array into the right shape for the model\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary:\n",
    "\n",
    "```python\n",
    "image.reshape((1, 28, 28, 1))\n",
    "```\n",
    "\n",
    "| Value | What it means          |\n",
    "| ----- | ---------------------- |\n",
    "| `1`   | One image (batch size) |\n",
    "| `28`  | Height of image        |\n",
    "| `28`  | Width of image         |\n",
    "| `1`   | Grayscale (1 channel)  |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to:\n",
    "\n",
    "* Visualize how image tensors look in memory?\n",
    "* Or go into how CNNs use these tensors to extract features?\n",
    "\n",
    "Let me know how deep you want to go!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e21f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010fef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ba64bd7",
   "metadata": {},
   "source": [
    "# 3. Differentiation\n",
    "\n",
    "Differentiation tells us how much change in output happens when we change the input ‚Äî this is called the derivative.\n",
    "\n",
    "**Imagine you're driving a car.**\n",
    "\n",
    "- Your speed is the derivative of distance over time.\n",
    "\n",
    "- If your speed is 50 km/h, it means your position changes 50 km every 1 hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd13f4e",
   "metadata": {},
   "source": [
    "**In deep learning:**\n",
    "\n",
    "We use derivatives to know how much to change weights in a neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8ed73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "# Example with autograd (PyTorch)\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96248f19",
   "metadata": {},
   "source": [
    "Great question! üî•\n",
    "Understanding this line is **fundamental** to using **PyTorch for deep learning**, especially when working with **automatic differentiation**.\n",
    "\n",
    "Let‚Äôs break this down:\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Code:\n",
    "\n",
    "```python\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "```\n",
    "\n",
    "This line creates a **PyTorch tensor** named `x` with the value `2.0`, and tells PyTorch to **track operations on it** for automatic **gradient computation**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Breaking it down:\n",
    "\n",
    "### ‚úÖ `2.0` ‚Äî the value of the tensor\n",
    "\n",
    "* You are creating a tensor that contains the number **2.0**\n",
    "* The `.0` makes it a **float**, which is necessary for gradient calculations\n",
    "* In deep learning, we typically use `float32` or `float64` data types\n",
    "\n",
    "üìå Equivalent in NumPy:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "x = np.array(2.0)  # a simple scalar value\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `requires_grad=True` ‚Äî enables gradient tracking\n",
    "\n",
    "This tells PyTorch:\n",
    "\n",
    "> \"I want to **track all operations** done on this tensor, so I can compute **gradients** later.\"\n",
    "\n",
    "### üìò Why is this important?\n",
    "\n",
    "* In **training neural networks**, we use **gradient descent** to update model parameters (weights).\n",
    "* To do that, we need to calculate the **derivative** of the loss w\\.r.t. each parameter.\n",
    "* `requires_grad=True` lets PyTorch build a **computational graph** and do **automatic differentiation**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Example:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)  # we want to track this value\n",
    "y = x ** 2                                 # y = x¬≤ = 4.0\n",
    "y.backward()                               # calculate dy/dx\n",
    "\n",
    "print(x.grad)                              # Output: tensor(4.0)\n",
    "```\n",
    "\n",
    "### üß† Why is the gradient 4.0?\n",
    "\n",
    "Because:\n",
    "\n",
    "* `y = x¬≤`\n",
    "* `dy/dx = 2x`\n",
    "* When `x = 2`, `dy/dx = 2 √ó 2 = 4`\n",
    "\n",
    "So, `x.grad` becomes `4.0`\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary:\n",
    "\n",
    "| Part                 | Meaning                                                        |\n",
    "| -------------------- | -------------------------------------------------------------- |\n",
    "| `2.0`                | The actual scalar value stored in the tensor                   |\n",
    "| `requires_grad=True` | Tells PyTorch to **track operations** for gradient computation |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ In Real Neural Networks\n",
    "\n",
    "When you create model weights:\n",
    "\n",
    "```python\n",
    "weight = torch.randn(1, requires_grad=True)\n",
    "```\n",
    "\n",
    "You **always** set `requires_grad=True`, so you can **update them during training** using gradient descent.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to see:\n",
    "\n",
    "* A full example where a simple linear model is trained?\n",
    "* Or how `.backward()` and `.grad` are used in a real loss function?\n",
    "\n",
    "Let me know ‚Äî you‚Äôre learning fast and asking the right questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21eb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be42c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "923c0c21",
   "metadata": {},
   "source": [
    "## ‚õ∞Ô∏è 4. **Gradient**\n",
    "\n",
    "The **gradient** is a collection of all the **partial derivatives**.\n",
    "\n",
    "### üß† Analogy:\n",
    "\n",
    "Imagine you're hiking down a mountain, and you want to find the **fastest way down**.\n",
    "\n",
    "* Gradient tells you:\n",
    "  ‚ÄúIf you step a little this way, the ground goes downhill faster.‚Äù\n",
    "* In deep learning:\n",
    "  Gradient tells us **how to adjust the weights to reduce the error**.\n",
    "\n",
    "üìå Gradient is **a vector pointing in the direction of fastest increase**.\n",
    "But we go in the **opposite direction** to **reduce loss** (that‚Äôs called gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53763f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015700fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f55b350",
   "metadata": {},
   "source": [
    "## ‚¨áÔ∏è 5. **Gradient Descent**\n",
    "\n",
    "### üîç What is it?\n",
    "\n",
    "A method to **find the best model** by gradually updating weights to reduce the loss (error).\n",
    "\n",
    "### üß† Simple Idea:\n",
    "\n",
    "1. Start with random weights\n",
    "2. Calculate how bad the prediction is (loss)\n",
    "3. Use gradients to adjust the weights to make the loss smaller\n",
    "4. Repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6246ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0000000004074074\n",
      "2.593450360578931e-19\n"
     ]
    }
   ],
   "source": [
    "# Simple idea (not full code)\n",
    "\n",
    "weight = 5.0\n",
    "learning_rate = 0.1\n",
    "\n",
    "for step in range(100):\n",
    "  loss = (weight - 3) ** 2\n",
    "  # print(\"Loss: \", loss)\n",
    "  grad = 2 * (weight - 3)\n",
    "  # print(\"Grad: \", grad)\n",
    "  weight -= learning_rate * grad\n",
    "\n",
    "print(weight)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bfec2",
   "metadata": {},
   "source": [
    "Excellent! You're looking at the **core idea behind how deep learning learns** ‚Äî this is a simple, clean example of **Gradient Descent**. üí°\n",
    "Let me explain it step-by-step in the **most beginner-friendly** way with real-life analogy.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Code Recap:\n",
    "\n",
    "```python\n",
    "weight = 5.0\n",
    "learning_rate = 0.001\n",
    "\n",
    "for step in range(100):\n",
    "    loss = (weight - 3) ** 2\n",
    "    grad = 2 * (weight - 3)\n",
    "    weight -= learning_rate * grad\n",
    "\n",
    "print(weight)\n",
    "print(learning_rate)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is this code trying to do?\n",
    "\n",
    "It‚Äôs trying to find the value of `weight` that makes the **loss** smallest.\n",
    "\n",
    "The loss function is:\n",
    "\n",
    "```python\n",
    "loss = (weight - 3)¬≤\n",
    "```\n",
    "\n",
    "So the **goal is to make weight = 3**, because that‚Äôs when the loss becomes zero.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Real-Life Analogy:\n",
    "\n",
    "Imagine you‚Äôre standing on a hill and trying to **reach the bottom**.\n",
    "At every step:\n",
    "\n",
    "* You check how steep the slope is (the gradient).\n",
    "* You take a small step **downhill** in the direction that reduces height fastest.\n",
    "* Eventually, you reach the **lowest point** ‚Äî that's when the gradient is zero.\n",
    "\n",
    "In our case:\n",
    "\n",
    "* The **height of the hill = loss**\n",
    "* The **position = weight**\n",
    "* The **slope = gradient**\n",
    "* The **step size = learning\\_rate**\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Line-by-Line Explanation\n",
    "\n",
    "### üî∏ `weight = 5.0`\n",
    "\n",
    "We **start** at position 5.0 ‚Äî not the correct value.\n",
    "\n",
    "### üî∏ `learning_rate = 0.001`\n",
    "\n",
    "How big each step should be. Small steps = slow but safe learning.\n",
    "\n",
    "### üîÑ Loop 100 times:\n",
    "\n",
    "We slowly walk toward the right value (`3.0`), step by step.\n",
    "\n",
    "#### Inside the loop:\n",
    "\n",
    "1. **Loss function**:\n",
    "\n",
    "   ```python\n",
    "   loss = (weight - 3) ** 2\n",
    "   ```\n",
    "\n",
    "   This measures how far `weight` is from `3`.\n",
    "   The closer `weight` is to 3, the smaller the loss.\n",
    "\n",
    "2. **Gradient (derivative)**:\n",
    "\n",
    "   ```python\n",
    "   grad = 2 * (weight - 3)\n",
    "   ```\n",
    "\n",
    "   This tells how fast the loss changes with respect to weight.\n",
    "\n",
    "3. **Update rule (gradient descent)**:\n",
    "\n",
    "   ```python\n",
    "   weight -= learning_rate * grad\n",
    "   ```\n",
    "\n",
    "   Move `weight` in the **opposite direction** of the gradient (downhill).\n",
    "\n",
    "---\n",
    "\n",
    "## üîö After the Loop:\n",
    "\n",
    "You print the final value of `weight`. It should be **very close to 3.0** (depending on learning rate and steps).\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Output Example:\n",
    "\n",
    "```python\n",
    "2.819..., 0.001\n",
    "```\n",
    "\n",
    "* The weight gets **closer to 3** every step.\n",
    "* With more steps or a larger learning rate, it would get even closer.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary Table\n",
    "\n",
    "| Concept            | Meaning                                    |\n",
    "| ------------------ | ------------------------------------------ |\n",
    "| `weight`           | Parameter we're trying to learn            |\n",
    "| `loss`             | Shows how wrong our guess is               |\n",
    "| `gradient`         | Direction and steepness of error change    |\n",
    "| `learning_rate`    | How big a step we take during each update  |\n",
    "| `gradient descent` | Algorithm to update weights to reduce loss |\n",
    "\n",
    "---\n",
    "\n",
    "## üî• In Deep Learning:\n",
    "\n",
    "This is **exactly how neural networks learn weights** ‚Äî but with:\n",
    "\n",
    "* Multiple parameters (not just one like `weight`)\n",
    "* Complex loss functions (e.g., cross-entropy)\n",
    "* Backpropagation to calculate gradients\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to:\n",
    "\n",
    "* See this same concept using `PyTorch` or `TensorFlow`?\n",
    "* Or try plotting how weight changes visually?\n",
    "\n",
    "You're doing amazing ‚Äî this is the beating heart of training deep learning models! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d52577",
   "metadata": {},
   "source": [
    "üìò Summary Table\n",
    "\n",
    "| Concept           | Meaning                               | Simple Analogy                            |\n",
    "| ----------------- | ------------------------------------- | ----------------------------------------- |\n",
    "| Tensor            | Multi-dimensional array               | Like a list, table, or image grid         |\n",
    "| Tensor Operations | Math actions on tensors               | Add, reshape, dot product, etc.           |\n",
    "| Differentiation   | How output changes with input         | Like speed = change of distance over time |\n",
    "| Gradient          | Vector of partial derivatives         | Shows which direction to move             |\n",
    "| Gradient Descent  | Method to reduce loss using gradients | Like walking downhill to lowest point     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ad0cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00a816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d6112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
